1. 빈발 아이템 찾기
* Market-Basket Model
- Association rules : If-then rules about the contents of baskets
- Baskets, Items 
- Frequent Itemsets : sets of items that appear in >= s baskets ( s : minimum support )
- Support (for itemset I): number of baskets containing all items in I
- Confidence of a rule is the probability of j given I
conf(I->j) = support(I U j) / support(I)
- interesting Association Rules : high positive or negative interests
Interest(I -> j) = conf(I -> j) - Pr[j]

A long itemset contains an exponetial number of subitemsets
- Maximal frequent itemsets : there is no frequent superset
- Closed frequent itemsets : there is no frequent superset with the same support 

Mining association rules
1) find all frequent itemsets I
2) generate rules

Finding frequent itemsets
Data format
- assume data te kept in flast files
Computation model 모든 바스킷을 차례로 읽고 처음부터 끝까지. 데이타 파일에 얼마나 빨리 접근하느냐. 
- The main cost of mining dis-resident data is usually the number of disk I/)s
- Many association-rule algorithms read the data in passes - all baskets read in turn 
- The cost is measured by the number of passes an algorithm makes over the data
Main-memory bottleneck 메모리를 효율적을 사용하는 것이 중요 
- for many frequent-itemsets algorithms, main-memory is the critical resource
Fingding Frequent Pairs
- naive algorithm은 메모리 용량을 초과한 사용 위험. 
- A-Priori algorithm, 'pruning' 가지치기

A-Priori Algorithm 
- a multi-pass algoritm for mining frequent itemsets im main memory
- pruning by monotonicity
- main-memory
 pass1 : item counts, 
 pass2 : frequent items, counts of pairs of frequent items(candidate pairs)

PCY Algorithm
- A-Priori,  hash 
- main memory
 pass1 : item counts, hash talble for pairs
 pass2 : frequent items, bitmap, counts of candidate pairs
PCY - Multistage Version
PCY - Multihash

Frequent Itemsets in<2 Passes algorithm : Random sampling, SON
Random samplig
- random sample of the market baskets, a-priori
- error : false positive, false negative

SON
- divide the data intok chunks, chunks are processed sequentially (not sampling)


2. 링크 분석
* PageRank Flow Model 
* Random walk
* Markov Process Theory 
* Google's solution : random teleport 
* Topic-specific PageRank (teleport set)
* term spam
*Link spam , Link Farm
* combating spam
* TrustRank for combating the Web Spam
* HITS:Hub and Authority Algorithm


3. 추천시스템

* 수많은 정보의 시대에서 적당한 정보를 얻기위한 방법 : 추천
- offline recommendation : popular item
- online recommendation : scarce items can be recommended, personalized
* Utility Function : u(x,s)->R 
* Utility Matrix
* 추천 단계
- Gater known ratings for maxtix 
-- Explicit ratings, Implicit ratings(clicks, visits, search keyword, purchases, ...)
- Predict unkown ratings from the known ratings
-- content-based, collaborative filtering, Latent factor
- Evalute predictions
* 추천 시스템 문제
- cold-start problem : new users 정보 부족으로 추천 어려움
- Data sparsity problem 새로운 제품의 초기 데이터 부족으로 추천 어려움

* Content-based recommendations
- 유사한 아이템 추천 
- movie recommendations, news recommendations
- Items Profiles. 
- TF-IDF for text
- User Profile
- 비디오, 오디오, 이미지 어려움. 초기 사용자 프로필 작성 어려움. 인기 아이템 추천이 안될수도.

* Collaborative Filtering CF
- User-User CF
- Item-Item CF
- 장점 work for any items
- 단점 cold start, sparsity, popularity bias

* Hybrid methods
- average score, majority vote
- add content-based method to CF

* Evaluating Recommender System
- RMSE Root-Mean-square error 
- Rank Correlation. Spearman correlation 
- accuracy 뿐 아니라  다양성도 중요





